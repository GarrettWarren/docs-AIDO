# Challenge `LF` {#lf status=ready}

The first task of the *AI Driving Olympics* is "Lane following".

In this task, we ask participants to submit code allowing the Duckiebot to drive on the right-hand side of the street within Duckietown without a specific goal point. Duckiebots will drive through the Duckietown and will be judged on how fast they drive, how well they follow the rules and how smooth or "comfortable" their driving is. Please refer to the following [video of a lane following demo](https://drive.google.com/file/d/198iythQkovbQkzY3pPeTXWC8tTCRgDwB/view?usp=sharing) for a short demonstration. A description of the [specific rules](#part:aido-rules) is provided.


The task is designed in a way that should allow for a completely \emph{reactive} algorithm design. This meant to say that to accomplish the task, it should not be strictly necessary to keep past observations in memory. In particular intersections will not be part of this challenge. Intersections will be recognized and maneuvered using provided code from the organizers.


To better illustrate the "Lane following" task we provide [](#bird_eye_lf), [](#ego_view_lf), [](#bird_eye_lf_crossing) and [](#ego_view_lf_crossing).


<div figure-id="fig:views1">
    <img src="images/in_lane.jpg" figure-id="subfig:bird_eye_lf"/>
    <img src="images/in_lane_sideview.jpg" figure-id="subfig:ego_view_lf"/>
</div>


<div figure-id="fig:views2">
    <img src="images/crossing_lane.jpg" figure-id="subfig:bird_eye_lf_crossing"/>
    <img src="images/crossing_lane_sideview.jpg" figure-id="subfig:ego_view_lf_crossing"/>
</div>


<style>
#fig\:views1 img,
#fig\:views2 img {
width: 20em;
}
</style>


## Evaluation

The lane following task is evaluated on three separate objectives.

### Performance objective

The [*performance objective*](#performance_lf) measures how fast a Duckiebot moves.


### Traffic law objective

The following traffic laws apply in the lane following task.

* [Staying in the lane](#traffic_laws_lf)



### Comfort objective

The following objective quantifies how "comfortable" a Duckiebot is driving.

[Comfortable driving](#comfort_embodied)


## Challenge `aido1_LF`: Lane Following {#challenge-aido1_lf1 status=ready}

The current version of the lane following challenge is `aido1_LF1_r3-v3`.
The lane following challenge tests an agent using a simulator.

Here is how the simulator looks:

<video autoplay="1" controls="1" loop="1" style="border: solid 1px black" width="320">
  <source src="http://duckietown-ai-driving-olympics-1.s3.amazonaws.com/v3/frankfurt/by-value/sha256/db648be4473470451c3ff8131f5c9a96849c812ab30db88ea48e61e089c60405" type="video/mp4"/>
</video>
 
* Check out the [Leaderboard](https://challenges.duckietown.org/v4/humans/challenges/aido1_LF1_r3-v3/leaderboard) to see who's currently winning!
 

* This challenge uses the Duckietown challenge infrastructure. The precise definition of the challenge is in the [challenge definition repository](https://github.com/duckietown/challenge-aido1_lf1)

To get started, try on of the existing templates:

* The [random template](#minimal-template) is the most flexible
* The [Tensorflow template](#tensorflow-template) is the place to submit a [tensorflow](https://www.tensorflow.org/) submission
* The [Pytorch template](#pytorch-template) is the place to submit a [pytorch](https://pytorch.org/) submission
* The [ROS baseline](#ros-template) is the place to submit a submission using the [Robot Operating System](http://www.ros.org/). 

Interaction protocol: [`aido1_remote3-v3`](#aido1_remote3-v3)

### Simulator parameters

The Duckietown Gym Parameters are [available here](https://challenges.duckietown.org/v4/humans/challenges/aido1_LF1_r3-v3#step1-simulation).

In particular:

```yaml
DTG_EPISODES: 5
DTG_STEPS_PER_EPISODE: 500
DTG_MAP: loop_obstacles
```

### Metrics 

Metrics are [described here](https://challenges.duckietown.org/v4/humans/challenges/aido1_LF1_r3-v3#scoring).





 



 
